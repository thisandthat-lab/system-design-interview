- 은행에서 전자 지갑으로 돈을 넣어두고, 전자상거래 사이트에서 전자 지갑의 돈을 사용하여 결제한다.
- 수수료 부과 없이 전자 지갑 간 이체 기능도 지원한다.

# 1단계. 문제 이해 및 설계 범위 확정

### 기능 요구사항

- 두 전자 지갑 사이의 이체 기능에만 집중한다. (환전은 고려하지 않음)

### 비기능 요구사항

- 1,000,000 TPS (백만) 지원
- 트랜잭션 보증 및 재현성(처음부터 데이터를 재생하여 언제든지 과거 잔액 재구성) 제공
- 99.99%의 가용성

### 개략적 추정

- 일반적인 트랜잭션 기반 DB는 수천 TPS를 지원한다.
    - 노드당 1,000TPS를 지원한다고 가정
        
        → 1,000개의 노드가 필요할까?🤔
        
        → **이체 연산은 인출 연산, 입금 연산 2개의 연산으로 이루어진다.**
        
        → 2,000개의 노드가 필요하다.
        
- 이번 장의 설계 목표 중 하나는 단일 노드가 처리할 수 있는 트랜잭션 수를 늘리는 것이다.

# 2단계. 개략적 설계안 제시 및 동의 구하기

## API 설계

### ✅ POST /v1/wallet/balance-transfer

- 한 지갑에서 다른 지갑으로 자금을 이체한다.
- request payload
    - from_account, to_account, **amount(string)**, currency, transaction_id
    
    <aside>
    💡 double/float 타입의 정밀도 이슈로 amount는 string 타입으로 전달한다.
    
    </aside>
    
- response
    - status, transaction_id

## 인메모리 샤딩

### 레디스

- `<사용자, 잔액>` 관계를 나타내기 좋은 자료구조는 map 또는 **키-값 저장소**이다.
- 인메모리 저장소로 인기 있는 **레디스**를 사용할 때, 한 대로 100만 TPS를 처리하기는 벅차다.
    
    → 클러스터를 구성하고 사용자 계정을 모든 노드에 균등하게 분산시키는 **파티셔닝** 또는 **샤딩** 전략을 사용해야한다.
    

### 주키퍼

- 모든 레디스 노드의 파티션 수와 주소는 한 군데 저장해놓는데, 이를 위해 **주키퍼**를 사용한다.

### 지갑 서비스

- 이체 명령 수신, 이체 명령의 유효성 검증, **이체에 관계된 두 계정의 잔액 갱신**을 담당한다.
    - 이 때 두 계정은 서로 다른 레디스 노드에 저장되어 있을 수 있는데, 주키퍼에 샤딩 정보를 질의하여 노드를 찾는다.
    - 두 업데이트는 하나의 원자적 트랜잭션으로 실행되어야 한다.

## 분산 트랜잭션

### 데이터베이스 샤딩

- 서로 다른 두 개 노드 갱신 연산을 원자적으로 수행하기 위해 각 레디스 노드를 **트랜잭션이 지원되는 RDB 노드**로 교체한다.
    
    → 이렇게 해도 두 작업이 정확히 동시에 처리된다는 보장이 없다.
    
    → **분산 트랜잭션**에 대해 알아본다.
    
    - 분산 시스템에서 한 트랜잭션에는 여러 노드의 프로세스가 관여할 수 있다.
    - 분산 트랜잭션은 이들 프로세스를 하나의 원자적인 트랜잭션으로 묶는다.

### 분산 트랜잭션: 2단계 커밋 (저수준 방안)

- 처리 흐름
    - 조정자(지갑 서비스)는 여러 DB에 읽기 및 쓰기 작업을 수행한다. (락이 걸림)
    - 애플리케이션이 트랜잭션 커밋을 요청하면, 조정자는 모든 DB에 트랜잭션 준비를 요청한다. **(1 Phase)**
    - 모든 DB가 ‘예’를 응답하면, 조정자는 모든 DB에 트랜잭션 커밋을 요청한다. **(2 Phase)**
        - 이 때 어느 한 DB라도 ‘아니오’를 응답하면, 조정자는 모든 DB에 트랜잭션 중단을 요청한다.
- 이 방식의 단점
    - 이기종 데이터베이스 사이에 2PC를 실행하려면, 모든 데이터베이스가 X/Open XA 표준을 만족해야 한다.
    - 다른 노드의 메시지를 기다리는 동안 락이 걸려 있어 성능이 좋지 않다.
    - 조정자가 SPOF가 될 수 있다.

### 분산 트랜잭션: TC/C (고수준 방안)

- 처리 흐름
    - 조정자는 모든 DB에 트랜잭션에 필요한 자원 예약을 요청한다.
    - 조정자는 모든 DB로부터 회신을 받는다.
        - 모두 ‘예라고 응답하면, 모든 데이터베이스에 작업 확인을 요청한다. **(Try-Confirm)**
        - 하나라도 ‘아니오’라고 응답하면, 모든 데이터베이스에 작업 취소를 요청한다. **(Try-Cancel)**
- TC/C는 보상 기반 분산 트랜잭션이라고도 부른다.
- 이 방식의 장점
    - 특정 DB에 구애 받지 않는다.
- 이 방식의 단점
    - 애플리케이션 레벨의 비즈니스 로직에서 세부 사항을 관리해야 한다.

<aside>
💡 **2PC vs TC/C**

- 2PC는 두 단계가 하나의 트랜잭션 안에서 실행되고, TC/C는 두 단계가 별도의 트랜잭션으로 실행된다.
    - TC/C 2단계에서 오류가 발생하면 이전 트랜잭션 결과를 상쇄하는 새로운 트랜잭션을 실행한다.
    - 오류 발생을 대비하여 TC/C의 진행 상황, 각 단계 상태 정보를 DB에 저장한다.
</aside>

<aside>
💡 **불균형 상태**

- 분산 트랜잭션 실행 도중에는 항상 데이터 불일치가 발생한다. (첫 번째 단계, 두 번째 단계 사이)
- 2PC라면 고려하지 않아도 되지만, TC/C같은 매커니즘을 사용하는 경우 직접 처리해야 한다.
</aside>

<aside>
💡 **잘못된 순서로 실행된 경우**

- 단계별 상태 테이블의 플래그를 활용해서 시도 명령 전에 취소 명령이 수행되지 않도록 한다.
</aside>

### 분산 트랜잭션: 사가

- 처리 흐름
    - 모든 연산은 순서대로 정렬되고, 각 연산은 자기 DB에서 독립적인 트랜잭션으로 실행된다.
    - 연산은 순서대로 실행되며, 한 연산이 완료되면 다음 연산이 개시된다.
    - 연산이 실패하면 전체 프로세스는 역순으로 보상 트랜잭션을 통해 롤백된다.
- 연산 실행 순서 조율 패턴
    - **Choreography 패턴**: MSA에서 모든 서비스가 다른 서비스의 이벤트를 구독하여 작업 수행 (탈중앙화)
    - **Orchestration 패턴**: 하나의 조정자가 모든 서비스가 올바른 순서로 작업을 실행하도록 조율
    
    → 일반적으로는 Orchestration 패턴을 선호한다.
    

<aside>
💡 **TC/C vs 사가**

- 보상 트랜잭션이 실행되는 시점이 TC/C는 취소 단계, 사가는 롤백 단계이다.
- TC/C에서는 실행 순서 보장이 되지 않고, 사가에서는 선형적으로 실행된다.

→ 지연 시간 요구사항이 없거나, 서비스 수가 적다면 아무거나 사용해도 되는데 주로 사가 패턴을 사용한다.

→ 지연 시간에 민감하고 많은 서비스/운영이 관계된 시스템이라면 TC/C가 더 낫다.

</aside>

## 이벤트 소싱

> *특정 시점의 계정 잔액을 알 수 있나요?
과거 및 현재 계정 잔액이 정확한지 어떻게 알 수 있나요?
코드 변경 후에도 시스템 로직이 올바른지 어떻게 검증하나요?*
> 

### 정의

- **명령(command)**
    - 외부에서 전달된, 의도가 명확한 요청이다.
    - 이벤트 소싱에서 순서는 아주 중요하기 때문에, FIFO 큐에 저장된다.
- **이벤트(event)**
    - 의도가 명확하지만, fact는 아니므로 유효하지 않을 수도 있다.
    - 작업 이행 전 반드시 유효성 검사를 해야 하고, 검사를 통과한 명령은 반드시 이행되어야 한다.
    - 이벤트 순서는 명령 순서를 따라야 하므로 FIFO 큐에 저장된다.
    
    <aside>
    💡 **명령 vs 이벤트**
    
    - 이벤트는 검증된 사실로, 실행이 끝난 상태이다.
    - 명령에는 무작위성 및 I/O가 포함될 수 있지만, 이벤트는 결정론적이다. (이벤트는 과거에 실제로 있었던 일)
    - 하나의 명령으로 여러 이벤트가 만들어질 수 있다.
    </aside>
    
- **상태(state)**
    - 이벤트가 적용될 때 변경되는 내용이다.
- **상태 기계(state machine)**
    - 이벤트 소싱 프로세스를 구동한다.
        - 명령의 유효성을 검사하고 이벤트를 생성한다.
        - 이벤트를 적용하여 상태를 갱신한다.
    - 결정론적으로 동작해야 하므로 무작위성을 내포할 수 없다.
    - 이벤트를 상태에 반영하는 것 또한 항상 같은 결과를 보장해야 한다.

### 재현성

- 이벤트를 처음부터 다시 재생하면 과거 잔액 상태를 언제든 재구성할 수 있다.
- 이벤트 리스트는 불변이고, 상태 기계 로직은 결정론적이므로 이벤트 이력을 재생하여 만들어낸 상태는 언제나 동일하다.
- 위에서 던진 세 가지 질문에 쉽게 답할 수 있다.
    
    → 감사 가능 시스템이어야 한다는 요건 때문에 이벤트 소싱이 지갑 서비스의 실질적인 솔루션으로 채택되는 경우가 많다.
    

### 명령-질의 책임 분리(CQRS)

- 상태를 공개하는 대신 모든 이벤트를 외부에 보내 외부 주체가 직접 상태를 재구축하도록 한다.
- 상태 기록을 담당하는 상태 기계는 하나, 읽기 전용 상태 기계는 여러 개 있을 수 있다.
- 읽기 전용 상태 기계는 상태 뷰를 만들고 쿼리에 이용한다.
- 읽기 전용 상태 기계는 결과적 일관성 모델을 따른다.

# 3단계. 상세 설계

## 고성능 이벤트 소싱

> AS-IS: Kafka를 명령 및 이벤트 저장소로, DB를 상태 저장소로 사용
> 

### 파일 기반의 명령 및 이벤트 목록

- **명령과 이벤트를 Kafka같은 원격 저장소가 아닌, 로컬 디스크에 저장한다.**
    - 네트워크를 통한 전송 시간 감소
    - 이벤트 목록은 추가 연산만 가능한 자료 구조에 저장하여 빠른 수행 속도 보장 (순차적 디스크 접근)
- **최근 명령과 이벤트를 `메모리`에 캐시한다.**

→ 구체적인 구현 방법: **mmap**을 사용한다. (로컬 디스크에 쓰는 동시에, 최근 데이터는 메모리에 자동으로 캐시)

### 파일 기반 상태

- 상태 정보도 로컬 디스크에 저장한다.
    - 파일 기반 로컬 관계형 데이터베이스, **SQLite**
    - 로컬 파일 기반 키-값 저장소, **LocksDB**
        - 쓰기 작업에 최적화된 자료 구조인 LSM을 사용한다.
        - 최근 데이터는 캐시하여 읽기 성능을 높인다.

### 스냅샷

- 모든 것이 파일 기반일 때, 재현 프로세스의 속도를 어떻게 높일 수 있을까?
    - 주기적으로(보통 금융 어플리케이션은 00:00) 스냅샷을 생성하여 특정 시점부터 이벤트를 처리할 수 있도록 한다.
- 스냅샷은 거대한 binary 파일이며, 일반적으로 HDFS같은 객체 저장소에 저장한다.

### ✅ 모든 것을 파일 기반으로 바꾸었다!

- 모든 것이 파일 기반일 때, 시스템은 컴퓨터 하드웨어의 I/O 처리량을 한계까지 최대로 활용할 수 있다.
- 하지만 로컬 디스크에 데이터를 저장하는 서버는 무상태가 아닌데다, SPOF가 될 가능성이 생기게 되었다…

## 신뢰할 수 있는 고성능 이벤트 소싱

### 신뢰성 분석

- 서버 노드가 하는 일: 데이터와 연산
    - 데이터 내구성이 보장되는 한, 연산 결과는 코드를 다른 노드에서 돌리면 복구 가능하다.
        
        → 데이터의 신뢰성이 훨씬 중요하다.
        
- 데이터 유형별 신뢰성 보장 방법
    - 파일 기반 상태 / 상태 스냅샷
        - 이벤트 목록을 재생하면 언제든 다시 만들 수 있다.
    - 파일 기반 명령 / 파일 기반 이벤트
        - 명령의 신뢰성 보장만으로는 불충분하고, 이벤트의 신뢰성 보장이 가장 중요하다.

### 합의

- 높은 안정성을 제공하기 위해 이벤트 목록을 여러 노드에 복제해야 하며, 아래 내용을 보장해야 한다.
    - 데이터 손실 없음
    - 로그 파일 내 데이터의 상대적 순서는 모든 노드에 동일
    
    → **합의 기반 복제** 방안이 적합하다.
    
    <aside>
    💡 **Raft 알고리즘**
    
    - 노드의 절반 이상이 온라인 상태면, 그 모두에 보관된 추가 전용 리스트는 같은 데이터를 가진다.
        - ex) 5개 노드 중 최소 3개 노드만 온라인 상태면 전체 시스템은 정상 동작한다.
    - 노드는 리더/후보/팔로워 세 가지 역할을 가질 수 있다.
        - 최대 하나의 노드만 리더가 되고, 나머지는 팔로워가 된다.
        - 리더는 외부 명령을 수신하고 클러스터 노드 간 데이터를 안정적으로 복제하는 역할을 한다.
    </aside>
    

### 고신뢰성 솔루션

- 위에서 설명한 복제 매커니즘을 활용하면 파일 기반 이벤트 소싱 아키텍처에서 SPOF 문제를 없앨 수 있다.
    - 리더는 외부에서 명령을 받아 이벤트로 변환하고, 래프트 알고리즘을 통해 이벤트를 모든 팔로워에 복제한다.
    - 래프트 알고리즘은 리더와 팔로워가 동일한 이벤트 목록을 갖도록 한다.
    - 이벤트 소싱은 동일한 이벤트 목록에서 항상 동일한 상태가 만들어지도록 한다.
- 래프트 알고리즘에서 장애가 발생했을 때 처리 프로세스
    - 리더 장애
        - 나머지 정상 노드 중에서 새 리더를 선출하여 순단 없이 서빙되도록 한다.
        - 명령 목록이 이벤트로 변환되기 전 장애가 발생하면 timeout을 리턴하여 클라이언트로부터 새로 명령을 받는다.
    - 팔로워 장애
        - 해당 팔로워로 전송된 요청은 실패하고, 래프트는 노드가 재시작되거나 대체될 때가지 재시도한다.

### 🥵 고성능 이벤트 소싱 아키텍처의 문제점

- CQRS 시스템에서는 요청/응답 흐름이 느릴 수 있다.
- 단일 래프트 그룹의 용량은 제한되어 있어서, 일정 규모 이상에서는 데이터를 샤딩하고 분산 트랜잭션을 구현해야 한다.

## 분산 이벤트 소싱

### 풀 모델 vs 푸시 모델

- 풀 모델에서 주기를 너무 짧게 설정하면 지갑 서비스의 과부하가 걸릴 수도 있다.

→ 외부 사용자와 이벤트 소싱 노드 사이에 **reverse proxy**를 추가하여 개선한다.

- 사용자는 프록시에 명령을 보내고, 프록시는 명령을 이벤트 소싱 노드로 전달하면서 주기적으로 실행 상태를 질의한다.
- 읽기 전용 상태 기계를 수정하여 응답 속도를 높일 수 있다.
    - 이벤트를 수신하자마자 실행 상태를 프록시에 푸시하도록 한다.
    - 사용자에게 실시간으로 응답이 이루어지는 느낌을 줄 수 있다.

### 분산 트랜잭션 (최종 모델)

- 모든 이벤트 소싱 노드 그룹이 동기적 실행 모델을 채택하면 TC/C나 사가 같은 분산 트랜잭션 솔루션을 재사용할 수 있다.

<img width="645" alt="image" src="https://github.com/thisandthat-lab/system-design-interview/assets/132281360/456604f4-12dc-4832-b57f-08928d81b221">

1. 사용자는 조정자에게 분산 트랜잭션(2개의 연산)을 보낸다.
2. 조정자는 단계별 상태 테이블에 레코드를 생성하여 트랜잭션 상태를 추적한다.

---

**[파티션 1(계정 A) → 파티션 2(계정 C) 순서로 각각 실행됨]**

1. 조정자는 작업 순서를 검토하여 A 계정 정보가 있는 파티션 1로 명령을 보낸다. (9번)
2. 래프트 리더는 명령을 수신하여 목록에 저장하고, 명령을 이벤트로 변환하여 동기화 완료 후 이벤트를 실행한다. (10번)
3. 파티션이벤트 소싱 프레임워크가 CQRS를 사용하여 데이터를 읽기 경로로 동기화한다. (11번)
4. 읽기 경로는 이벤트 소싱 프레임워크를 호출한 조정자에 상태를 푸시한다. (12번)
5. 조정자는 파티션 1에서 성공 상태를 수신한다. (13번)
6. 조정자는 단계별 상태 테이블에 파티션 1의 작업이 성공했음을 나타내는 레코드를 생성한다. (14번)

---

1. 모든 작업이 성공하고 분산 트랜잭션이 완료되면 조정자는 호출자에게 결과를 응답한다.

# 4단계. 마무리

- 100만 TPS 이상의 결제 명령을 처리하기 위해서는 수천 개 노드가 필요하다.
    - 레디스 같은 인메모리 키-값 저장소 사용 → 데이터 내구성 부실
    - 분산 트랜잭션 DB 사용 → 데이터 감사의 어려움
    - 외부 DB와 큐를 사용한 이벤트 소싱 → 성능이 떨어짐
    - 파일 기반 이벤트 소싱 → SPOF 문제
    - 래프트 합의 알고리즘 + CQRS를 활용한 분산 이벤트 소싱 👍🏻
        - 역방향 프록시 추가
        - TC/C 또는 사가 프로토콜을 사용하여 여러 노드에 명령 실행 조율
