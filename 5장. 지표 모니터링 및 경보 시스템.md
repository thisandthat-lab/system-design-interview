# 5장_지표 모니터링 및 경보 시스템

- 유명한 것: Datadog, Prometheus, Grafana 등등..

# 1단계. 문제 이해 및 설계 범위 확정

## 개략적 요구사항 및 가정

- 대규모 인프라를 모니터링해야 한다.
    - DAU 1억
    - 서버 풀 1,000개, 풀 당 서버 수 100개 
    → 서버 당 100개의 운영 지표를 수집한다면 모니터링해야 하는 지표 수는 천만 개
    - 데이터 보관 기간은 1년
        - 새로 수집한 데이터는 7일간 보관
        - 7일 뒤에는 1분 단위 데이터로 만들어 30일간 보관
        - 그 후에는 1시간 단위 데이터로 변환하여 보관
- 모니터링 필요한 지표
    - 회사 내부 시스템 운영 지표(CPU, 메모리, 디스크 사용량, rps 등)를 수집하는 시스템

### 비기능 요구사항

- 규모 확장성: 지표 수와 경보의 양에 맞게 확장될 수 있어야 한다.
- 낮은 응답 지연: 대시보드, 경보를 신속히 처리할 수 있도록 질의에 대한 낮은 응답 지연을 보장해야한다.
- 안정성: 중요 경보를 놓치지 않아야 한다.
- 유연성

# 2단계. 개략적 설계안 제시 및 동의 구하기

## 지표 모니터링 및 경보 시스템 컴포넌트

- **데이터 수집**: 여러 컴포넌트로부터 지표 데이터 수집
- **데이터 전송**: 지표 데이터를 지표 모니터링 시스템으로 전송
- **데이터 저장소**: 전송된 데이터를 정리하고 저장
- **경보(alerting)**: 데이터를 분석하고, 이상 징후를 감지하고, 경보를 발생시킨다.
- **시각화**: 데이터를 차트나 그래프 등으로 제공한다.

## 데이터 모델

- 시계열(값 집합에 타임스탬프가 붙은 형태) 데이터 형태로 기록한다.
    - matric_name
    - labels
    - timestamp
    - value

### 데이터 접근 패턴

- 쓰기 부하가 막대하다.
- 읽기 부하는 일시적으로 치솟았다 사라진다. (spiky)
    - 시각화, 경보 서비스에서 읽기 연산 발생

## 데이터 저장소 시스템

- 범용 데이터베이스는 본 시스템의 부하 규모에 맞추려면 전문가 수준의 튜닝이 필요하다.
    - 특히 RDB는 시계열 데이터 연산에 최적화되어 있지 않다.
    - 많은 양의 쓰기 연산이 지속적으로 발생하는 환경에서 좋은 성능을 보이지 못한다.
- 시계열 데이터에 최적화 된 저장소 시스템
    - OpenTSDB, MetricsDB, Timestream, **InfluxDB, Prometheus**

## 개략적 설계안

### 지표 출처(metrics source)

- 지표 데이터가 만들어지는 곳
- 애플리케이션 서버, SQL DB, MQ 등

### 지표 수집기(metric collector)

- 지표 데이터를 수집하고 시계열 데이터에 기록

### 시계열 데이터베이스(time-series database)

- 지표 데이터를 시계열 데이터 형태로 보관하는 저장소
- 다량의 시계열 데이터를 분석하고 요약하는 데 적합하도록 설계된 질의 인터페이스 제공

### 질의 서비스(query service)

- 시계열 데이터베이스에 보관된 데이터를 질의하고 가져오는 과정을 돕는 서비스

### 경보 시스템(alerting service)

- 다양한 대상으로 경보 알림을 전송하는 서비스

### 시각화 시스템(visualization system)

- 지표를 다양한 형태의 그래프/차트로 시각화하는 기능을 제공하는 서비스

# 3단계. 상세 설계

## 지표 수집

- counter나 CPU 사용량 같은 지표를 수집할 때 데이터의 소실이 큰 문제는 아니다.

### 풀 모델 vs 푸시 모델 - 특징

- **풀 모델 - Prometheus**
    - 지표 수집기는 데이터를 가져올 서비스 목록을 알아야 한다. (서비스 엔드포인트 DNS/IP 정보 파일을 서버에 두기)
        - 각 서비스는 자신의 가용성 관련 정보를 **서비스 탐색 서비스(SDS)**에 기록한다.
        - SDS는 엔드포인트 목록에 변화가 새길 때마다 지표 수집기에 통보한다.
    - 지표 수집기가 SDS에서 목록을 확보하고, 지표 출처(웹, DB, 큐, 캐시) 등에서 지표를 주기적으로 pull한다.
    - 대용량의 지표를 수집하려면 지표 수집기 서버 풀을 만들어야 한다.
        - 여러 서버가 같은 출처에서 데이터를 중복해서 가져올 수 있기 때문에, **중재 매커니즘**이 존재해야 한다.
            - **안정 해시 링**을 사용해서, 해시 링 구간마다 담당 수집기 서버를 지정한다.
- **푸시 모델 - CloudWatch, Graphite**
    - 지표 출처가 직접 지표를 수집기에 전송한다.
    - 모니터링 대상 서버에 **수집 에이전트** 소프트웨어를 설치한다.
        - 에이전트는 지표 데이터를 받아 모은 다음 주기적으로 수집기에 전달한다.
        - 간단한 카운터 지표같은 경우 수집기에 보내기 전 에이전트가 직접 집계 작업 등을 처리할 수 있다. (효율적)
    - 데이터 전송 트래픽이 많아지면 일시적으로 수집기가 전송되는 데이터를 처리하지 못하게 될 수 있다.
        - 지표 수집기 클러스터 자체도 자동 규모 확장이 가능하도록 구성하고, 그 앞에 LB를 둔다. (오토스케일링)

### 풀 모델 vs 푸시 모델 - 장단점

- **풀 모델**
    - 디버깅과 헬스체크 측면에서는 풀 모델이 낫다.
    - TCP를 주로 사용한다.
    - 지표 서비스 목록을 수집기가 가지고 있으므로 데이터의 신뢰도가 높다.
- **푸시 모델**
    - 생명 주기가 짧은 프로세스 지표의 수집, 네트워크 인프라 관리 측면에서는 푸시 모델이 낫다.
    - UDP를 주로 사용한다. (풀 모델보다 전송 지연이 낮다.)
    - 아무나 수집기에 데이터를 보낼 수 있다. (수집기 측에 인증을 강제하여 문제를 해결할 수 있다.)

---

## 지표 전송 파이프라인의 규모 확장

- 지표 수집기는 엄청난 양의 데이터를 받아 처리해야 하며, 자동으로 규모 확장이 가능하도록 설정해야 한다.
- 시계열 데이터베이스에 장애가 생기면 데이터 손실이 발생할 가능성이 있다.

→ 지표 수집기와 시계열 데이터베이스 사이에 큐(Kafka)를 두어 문제를 해결한다.

→ Storm, Flink, Spark같은 컨슈머가 데이터를 받아 시계열 데이터베이스에 저장한다.

**💡위와 같이 큐를 두었을 때의 장점**

- 카프카는 고도로 안정적이고 규모 확장성이 뛰어난 분산 메시지 플랫폼이다.
- 데이터 수집 컴포넌트와 처리 컴포넌트 사이의 결합도를 낮춘다.
- 데이터베이스 장애가 생겨도 카프카에 보관되기 때문에 데이터가 소실되지 않는다.

### 카프카를 통한 규모 확장

- 카프카에 내장된 파티션 매커니즘을 사용한다.
    - 대역폭 요구사항에 따라 파티션 수를 설정한다.
    - 지표 이름에 따라 어떤 지표를 어느 파티션에 배치할 지 결정한다. → 컨슈머는 지표 이름에 따라 데이터 집계 가능
    - 태그/레이블에 따라 지표 데이터를 세분화한 파티션으로 나누고, 지표에 우선순위를 설정한다.

### 카프카의 대안

- 페이스북의 메모리 기반 시계열 데이터베이스 시스템 고릴라 …?
(근데 그냥 카프카를 제안하는 게 낫지 않을까요.. 고릴라보다는..)

---

## 데이터 집계 지점

- **수집 에이전트가 집계하기**
    - 수집 에이전트가 복잡한 집계 로직은 지원하지 않는다.
- **데이터 수집 파이프라인이 집계하기**
    - 데이터를 저장소에 기록하기 전에 집계하려면 스트림 프로세싱 엔진이 필요하다.
    - 늦게 도착하는 지표 데이터의 처리가 어렵고, 원본 데이터가 보관되지 않아 정밀도와 유연성이 떨어진다.
- **질의 시에 집계하기**
    - 데이터를 날것 그대로 보관하고 질의할 때 필요한 시간 구간에 맞게 집계한다.
    - 데이터가 손실되지는 않으나, 전체 데이터세트 대상으로 집계 결과를 계산해야 하므로 속도가 느리다.

## 질의 서비스

- 시각화 또는 경보 시스템에서 접수된 요청을 시계열 데이터베이스를 통해 처리하는 역할을 담당한다.
- 클라이언트(시각화 및 경보 시스템)와 시계열 데이터베이스 사이의 결합도를 낮출 수 있다.

### 캐시 계층

- 질의 결과를 캐시해두어 DB 부하를 낮추고, 질의 서비스 성능을 높일 수 있다.

### 질의 서비스를 두면 곤란한 경우

- 대부분 상용 시각화 및 경보 시스템은 시계열 데이터베이스 연동을 처리하는 플러그인을 갖추고 있다.
- 별도 캐시를 도입할 필요가 없는 시계열 데이터베이스가 있다는 것도 고려사항이다.

### 시계열 데이터베이스 질의어

- SQL이 아닌 Flux라는 언어로 작성하면 간단하다.

---

## 저장소 계층

### 저장 용량 최적화 방안

- 데이터 인코딩 및 압축
- 다운샘플링
    - 데이터의 해상도를 낮춰 저장소 요구량을 줄이는 기법
- 냉동 저장소
    - 잘 사용되지 않는 비활성 상태 데이터를 보관하는 곳

---

## 경보 시스템

- 경보 처리 흐름
    - 경보 규칙 설정 파일을 가져와 캐시 서버에 보관해두고, 경보 관리자가 해당 설정 내역을 캐시에서 가져온다.
    - 설정된 규칙에 근거하여 경보 관리자는 지정된 시간마다 질의 서비스를 호출한다.
        - 질의 결과가 설정된 임계값(threshold)을 위반하면 경보 이벤트를 생성한다.
        - 그 외 경보 필터링, 병합, 중복 제거, 접근 제어, 재시도 기능도 수행한다.
    - 모든 경보의 상태(비활성화, 응답 대기, 경보 발령, 문제 해결 등)는 카산드라 같은 키-값 저장소에 저장된다.
        - 알림이 적어도 한 번 전달되도록(retry) 보장한다.
    - 경보 이벤트를 카프카에 전달한다.
    - 경보 컨슈머는 카프카에서 경보 이벤트를 읽어 다양한 채널로 알림을 전송한다.
- 면접 때는 경보 시스템은 직접 만들지 말고 상용화 된 것 채택하겠다고 말하는 것이 좋겠다.

---

## 시각화 시스템

- 지표 대시보드에는 지표를 다양한 시간 범위로 표시하고, 경보 대시보드에는 다양한 경보 상태를 표시한다.
- 이것 또한 상용품을 구입해서 쓰자고 주장하자. ex) Grafana

# 4단계. 마무리

- LGTM🚀xa

<aside>
💡 서버와 DB 사이에 큐를 두는 것..
데이터가 소실될까봐 큐를 두었는데, 이렇게 생각하면 밑도 끝도 없어지지 않을까?
Kafka에 장애가 생기면..? 소실될텐데 그럼 Kafka 앞에 또 다른 큐를 둔다… 이런식으로 ..??

</aside>
